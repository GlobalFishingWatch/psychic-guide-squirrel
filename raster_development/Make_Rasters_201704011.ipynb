{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import uuid\n",
    "import time\n",
    "import subprocess\n",
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import csv\n",
    "import sys\n",
    "import numpy as np\n",
    "import gzip\n",
    "import rasterio as rio\n",
    "import affine\n",
    "import os.path\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class BigQuery:\n",
    "\n",
    "    def __init__(self):\n",
    "        credentials = GoogleCredentials.get_application_default()\n",
    "        self._bq = discovery.build('bigquery', 'v2', credentials=credentials)\n",
    "\n",
    "\n",
    "    # XXX allow dataset/table to be optional (should probably pass in as atomic `destination`)\n",
    "    # XXXX allow allowLargeResults to be optional\n",
    "    # XXX check that dataset/table set if not\n",
    "    # XXX ADD note that if dest table specified it is not automatically deleted\n",
    "    def async_query(self, project_id, query, dataset, table,\n",
    "                        batch=False, num_retries=5):\n",
    "        \"\"\"Create an asynchronous BigQuery query\n",
    "        MOAR DOCS\n",
    "        \"\"\"\n",
    "        # Generate a unique job_id so retries\n",
    "        # don't accidentally duplicate query\n",
    "        job_data = {\n",
    "            'jobReference': {\n",
    "                'projectId': project_id,\n",
    "                'job_id': str(uuid.uuid4())\n",
    "            },\n",
    "            'configuration': {\n",
    "                'query': {\n",
    "                    'allowLargeResults': 'true',\n",
    "                    'writeDisposition':'WRITE_TRUNCATE', #overwrites table\n",
    "                    'destinationTable' : {\n",
    "                      \"projectId\": project_id,\n",
    "                      \"datasetId\": dataset,\n",
    "                      \"tableId\": table,\n",
    "                      },\n",
    "                    'query': query,\n",
    "                    'priority': 'BATCH' if batch else 'INTERACTIVE'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        return self._bq.jobs().insert(\n",
    "            projectId=project_id,\n",
    "            body=job_data).execute(num_retries=num_retries)\n",
    "\n",
    "\n",
    "    def poll_job(self, job, max_tries=4000):\n",
    "        \"\"\"Waits for a job to complete.\"\"\"\n",
    "\n",
    "        request = self._bq.jobs().get(\n",
    "            projectId=job['jobReference']['projectId'],\n",
    "            jobId=job['jobReference']['jobId'])\n",
    "\n",
    "        trial = 0\n",
    "        while trial < max_tries:\n",
    "            result = request.execute(num_retries=2)\n",
    "\n",
    "            if result['status']['state'] == 'DONE':\n",
    "                if 'errorResult' in result['status']:\n",
    "                    raise RuntimeError(result['status']['errorResult'])\n",
    "                return\n",
    "\n",
    "            time.sleep(1)\n",
    "            trial += 1\n",
    "\n",
    "        raise RuntimeError(\"timeout\")\n",
    "\n",
    "\n",
    "    def async_extract_query(self, job, path, format=\"CSV\", compression=\"GZIP\",\n",
    "                                                        num_retries=5):\n",
    "        \"\"\"Extracts query specified by job into Google Cloud storage at path\n",
    "        MOAR docs\n",
    "        \"\"\"\n",
    "\n",
    "        job_data = {\n",
    "          'jobReference': {\n",
    "              'projectId': job['jobReference']['projectId'],\n",
    "              'jobId': str(uuid.uuid4())\n",
    "          },\n",
    "          'configuration': {\n",
    "              'extract': {\n",
    "                  'sourceTable': {\n",
    "                      'projectId': job['configuration']['query']['destinationTable']['projectId'],\n",
    "                      'datasetId': job['configuration']['query']['destinationTable']['datasetId'],\n",
    "                      'tableId': job['configuration']['query']['destinationTable']['tableId'],\n",
    "                  },\n",
    "                  'destinationUris': [path],\n",
    "                  'destinationFormat': format,\n",
    "                  'compression': compression\n",
    "              }\n",
    "          }\n",
    "        }\n",
    "        return self._bq.jobs().insert(\n",
    "            projectId=job['jobReference']['projectId'],\n",
    "            body=job_data).execute(num_retries=num_retries)\n",
    "\n",
    "\n",
    "def gs_mv(src_path, dest_path):\n",
    "    \"\"\"Move data using gsutil\n",
    "    This was written to move data from cloud\n",
    "    storage down to your computer and hasn't been\n",
    "    tested for other things.\n",
    "    Example:\n",
    "    gs_mv(\"gs://world-fishing-827/scratch/SOME_DIR/SOME_FILE\",\n",
    "                \"some/local/path/.\")\n",
    "    \"\"\"\n",
    "    subprocess.call([\"gsutil\", \"-m\", \"mv\", src_path, dest_path])\n",
    "\n",
    "\n",
    "# this function is to get the approximate area of a grid cell, \n",
    "# which can be used to normalize density. It currently isn't used\n",
    "def get_area(lat):\n",
    "    lat_degree = 69 # miles\n",
    "    # Convert latitude and longitude to \n",
    "    # spherical coordinates in radians.\n",
    "    degrees_to_radians = math.pi/180.0        \n",
    "    # phi = 90 - latitude\n",
    "    phi = (lat+cellsize/2.)*degrees_to_radians #plus half a cell size to get the middle\n",
    "    lon_degree = math.cos(phi)*lat_degree \n",
    "    # return 69*69*2.6\n",
    "    return  lat_degree*lon_degree* 2.58999 # miles to square km\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Execute the query, move the table to gcs, then download it\n",
    "# as a zipped csv file\n",
    "\n",
    "proj_id = \"world-fishing-827\"\n",
    "dataset = \"scratch_global_fishing_raster\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20150101\n",
      "20150102\n",
      "20150103\n",
      "20150104\n",
      "20150105\n",
      "20150106\n",
      "20150107\n",
      "20150108\n",
      "20150109\n",
      "20150110\n",
      "20150111\n",
      "20150112\n",
      "20150113\n",
      "20150114\n",
      "20150115\n",
      "20150116\n",
      "20150117\n",
      "20150118\n",
      "20150119\n",
      "20150120\n",
      "20150121\n",
      "20150122\n",
      "20150123\n",
      "20150124\n",
      "20150125\n",
      "20150126\n",
      "20150127\n",
      "20150128\n",
      "20150129\n",
      "20150130\n",
      "20150131\n",
      "20150201\n",
      "20150202\n",
      "20150203\n",
      "20150204\n",
      "20150205\n",
      "20150206\n",
      "20150207\n",
      "20150208\n",
      "20150209\n",
      "20150210\n",
      "20150211\n",
      "20150212\n",
      "20150213\n",
      "20150214\n",
      "20150215\n",
      "20150216\n",
      "20150217\n",
      "20150218\n",
      "20150219\n",
      "20150220\n",
      "20150221\n",
      "20150222\n",
      "20150223\n",
      "20150224\n",
      "20150225\n",
      "20150226\n",
      "20150227\n",
      "20150228\n",
      "20150301\n",
      "20150302\n",
      "20150303\n",
      "20150304\n",
      "20150305\n",
      "20150306\n",
      "20150307\n",
      "20150308\n",
      "20150309\n",
      "20150310\n",
      "20150311\n",
      "20150312\n",
      "20150313\n",
      "20150314\n",
      "20150315\n",
      "20150316\n",
      "20150317\n",
      "20150318\n",
      "20150319\n",
      "20150320\n",
      "20150321\n",
      "20150322\n",
      "20150323\n",
      "20150324\n",
      "20150325\n",
      "20150326\n",
      "20150327\n",
      "20150328\n",
      "20150329\n",
      "20150330\n",
      "20150331\n",
      "20150401\n",
      "20150402\n",
      "20150403\n",
      "20150404\n",
      "20150405\n",
      "20150406\n",
      "20150407\n",
      "20150408\n",
      "20150409\n",
      "20150410\n",
      "20150411\n",
      "20150412\n",
      "20150413\n",
      "20150414\n",
      "20150415\n",
      "20150416\n",
      "20150417\n",
      "20150418\n",
      "20150419\n",
      "20150420\n",
      "20150421\n",
      "20150422\n",
      "20150423\n",
      "20150424\n",
      "20150425\n",
      "20150426\n",
      "20150427\n",
      "20150428\n",
      "20150429\n",
      "20150430\n",
      "20150501\n",
      "20150502\n",
      "20150503\n",
      "20150504\n",
      "20150505\n",
      "20150506\n",
      "20150507\n",
      "20150508\n",
      "20150509\n",
      "20150510\n",
      "20150511\n",
      "20150512\n",
      "20150513\n",
      "20150514\n",
      "20150515\n",
      "20150516\n",
      "20150517\n",
      "20150518\n",
      "20150519\n",
      "20150520\n",
      "20150521\n",
      "20150522\n",
      "20150523\n",
      "20150524\n",
      "20150525\n",
      "20150526\n",
      "20150527\n",
      "20150528\n",
      "20150529\n",
      "20150530\n",
      "20150531\n",
      "20150601\n",
      "20150602\n",
      "20150603\n",
      "20150604\n",
      "20150605\n",
      "20150606\n",
      "20150607\n",
      "20150608\n",
      "20150609\n",
      "20150610\n",
      "20150611\n",
      "20150612\n",
      "20150613\n",
      "20150614\n",
      "20150615\n",
      "20150616\n",
      "20150617\n",
      "20150618\n",
      "20150619\n",
      "20150620\n",
      "20150621\n",
      "20150622\n",
      "20150623\n",
      "20150624\n",
      "20150625\n",
      "20150626\n",
      "20150627\n",
      "20150628\n",
      "20150629\n",
      "20150630\n",
      "20150701\n",
      "20150702\n",
      "20150703\n",
      "20150704\n",
      "20150705\n",
      "20150706\n",
      "20150707\n",
      "20150708\n",
      "20150709\n",
      "20150710\n",
      "20150711\n",
      "20150712\n",
      "20150713\n",
      "20150714\n",
      "20150715\n",
      "20150716\n",
      "20150717\n",
      "20150718\n",
      "20150719\n",
      "20150720\n",
      "20150721\n",
      "20150722\n",
      "20150723\n",
      "20150724\n",
      "20150725\n",
      "20150726\n",
      "20150727\n",
      "20150728\n",
      "20150729\n",
      "20150730\n",
      "20150731\n",
      "20150801\n",
      "20150802\n",
      "20150803\n",
      "20150804\n",
      "20150805\n",
      "20150806\n",
      "20150807\n",
      "20150808\n",
      "20150809\n",
      "20150810\n",
      "20150811\n",
      "20150812\n",
      "20150813\n",
      "20150814\n",
      "20150815\n",
      "20150816\n",
      "20150817\n",
      "20150818\n",
      "20150819\n",
      "20150820\n",
      "20150821\n",
      "20150822\n",
      "20150823\n",
      "20150824\n",
      "20150825\n",
      "20150826\n",
      "20150827\n",
      "20150828\n",
      "20150829\n",
      "20150830\n",
      "20150831\n",
      "20150901\n",
      "20150902\n",
      "20150903\n",
      "20150904\n",
      "20150905\n",
      "20150906\n",
      "20150907\n",
      "20150908\n",
      "20150909\n",
      "20150910\n",
      "20150911\n",
      "20150912\n",
      "20150913\n",
      "20150914\n",
      "20150915\n",
      "20150916\n",
      "20150917\n",
      "20150918\n",
      "20150919\n",
      "20150920\n",
      "20150921\n",
      "20150922\n",
      "20150923\n",
      "20150924\n",
      "20150925\n",
      "20150926\n",
      "20150927\n",
      "20150928\n",
      "20150929\n",
      "20150930\n",
      "20151001\n",
      "20151002\n",
      "20151003\n",
      "20151004\n",
      "20151005\n",
      "20151006\n",
      "20151007\n",
      "20151008\n",
      "20151009\n",
      "20151010\n",
      "20151011\n",
      "20151012\n",
      "20151013\n",
      "20151014\n",
      "20151015\n",
      "20151016\n",
      "20151017\n",
      "20151018\n",
      "20151019\n",
      "20151020\n",
      "20151021\n",
      "20151022\n",
      "20151023\n",
      "20151024\n",
      "20151025\n",
      "20151026\n",
      "20151027\n",
      "20151028\n",
      "20151029\n",
      "20151030\n",
      "20151031\n",
      "20151101\n",
      "20151102\n",
      "20151103\n",
      "20151104\n",
      "20151105\n",
      "20151106\n",
      "20151107\n",
      "20151108\n",
      "20151109\n",
      "20151110\n",
      "20151111\n",
      "20151112\n",
      "20151113\n",
      "20151114\n",
      "20151115\n",
      "20151116\n",
      "20151117\n",
      "20151118\n",
      "20151119\n",
      "20151120\n",
      "20151121\n",
      "20151122\n",
      "20151123\n",
      "20151124\n",
      "20151125\n",
      "20151126\n",
      "20151127\n",
      "20151128\n",
      "20151129\n",
      "20151130\n",
      "20151201\n",
      "20151202\n",
      "20151203\n",
      "20151204\n",
      "20151205\n",
      "20151206\n",
      "20151207\n",
      "20151208\n",
      "20151209\n",
      "20151210\n",
      "20151211\n",
      "20151212\n",
      "20151213\n",
      "20151214\n",
      "20151215\n",
      "20151216\n",
      "20151217\n",
      "20151218\n",
      "20151219\n",
      "20151220\n",
      "20151221\n",
      "20151222\n",
      "20151223\n",
      "20151224\n",
      "20151225\n",
      "20151226\n",
      "20151227\n",
      "20151228\n",
      "20151229\n",
      "20151230\n",
      "20151231\n",
      "20160101\n",
      "20160102\n",
      "20160103\n",
      "20160104\n",
      "20160105\n",
      "20160106\n",
      "20160107\n",
      "20160108\n",
      "20160109\n",
      "20160110\n",
      "20160111\n",
      "20160112\n",
      "20160113\n",
      "20160114\n",
      "20160115\n",
      "20160116\n",
      "20160117\n",
      "20160118\n",
      "20160119\n",
      "20160120\n",
      "20160121\n",
      "20160122\n",
      "20160123\n",
      "20160124\n",
      "20160125\n",
      "20160126\n",
      "20160127\n",
      "20160128\n",
      "20160129\n",
      "20160130\n",
      "20160131\n",
      "20160201\n",
      "20160202\n",
      "20160203\n",
      "20160204\n",
      "20160205\n",
      "20160206\n",
      "20160207\n",
      "20160208\n",
      "20160209\n",
      "20160210\n",
      "20160211\n",
      "20160212\n",
      "20160213\n",
      "20160214\n",
      "20160215\n",
      "20160216\n",
      "20160217\n",
      "20160218\n",
      "20160219\n",
      "20160220\n",
      "20160221\n",
      "20160222\n",
      "20160223\n",
      "20160224\n",
      "20160225\n",
      "20160226\n",
      "20160227\n",
      "20160228\n",
      "20160229\n",
      "20160301\n",
      "20160302\n",
      "20160303\n",
      "20160304\n",
      "20160305\n",
      "20160306\n",
      "20160307\n",
      "20160308\n",
      "20160309\n",
      "20160310\n",
      "20160311\n",
      "20160312\n",
      "20160313\n",
      "20160314\n",
      "20160315\n",
      "20160316\n",
      "20160317\n",
      "20160318\n",
      "20160319\n",
      "20160320\n",
      "20160321\n",
      "20160322\n",
      "20160323\n",
      "20160324\n",
      "20160325\n",
      "20160326\n",
      "20160327\n",
      "20160328\n",
      "20160329\n",
      "20160330\n",
      "20160331\n",
      "20160401\n",
      "20160402\n",
      "20160403\n",
      "20160404\n",
      "20160405\n",
      "20160406\n",
      "20160407\n",
      "20160408\n",
      "20160409\n",
      "20160410\n",
      "20160411\n",
      "20160412\n",
      "20160413\n",
      "20160414\n",
      "20160415\n",
      "20160416\n",
      "20160417\n",
      "20160418\n",
      "20160419\n",
      "20160420\n",
      "20160421\n",
      "20160422\n",
      "20160423\n",
      "20160424\n",
      "20160425\n",
      "20160426\n",
      "20160427\n",
      "20160428\n",
      "20160429\n",
      "20160430\n",
      "20160501\n",
      "20160502\n",
      "20160503\n",
      "20160504\n",
      "20160505\n",
      "20160506\n",
      "20160507\n",
      "20160508\n",
      "20160509\n",
      "20160510\n",
      "20160511\n",
      "20160512\n",
      "20160513\n",
      "20160514\n",
      "20160515\n",
      "20160516\n",
      "20160517\n",
      "20160518\n",
      "20160519\n",
      "20160520\n",
      "20160521\n",
      "20160522\n",
      "20160523\n",
      "20160524\n",
      "20160525\n",
      "20160526\n",
      "20160527\n",
      "20160528\n",
      "20160529\n",
      "20160530\n",
      "20160531\n",
      "20160601\n",
      "20160602\n",
      "20160603\n",
      "20160604\n",
      "20160605\n",
      "20160606\n",
      "20160607\n",
      "20160608\n",
      "20160609\n",
      "20160610\n",
      "20160611\n",
      "20160612\n",
      "20160613\n",
      "20160614\n",
      "20160615\n",
      "20160616\n",
      "20160617\n",
      "20160618\n",
      "20160619\n",
      "20160620\n",
      "20160621\n",
      "20160622\n",
      "20160623\n",
      "20160624\n",
      "20160625\n",
      "20160626\n",
      "20160627\n",
      "20160628\n",
      "20160629\n",
      "20160630\n",
      "20160701\n",
      "20160702\n",
      "20160703\n",
      "20160704\n",
      "20160705\n",
      "20160706\n",
      "20160707\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8d7b0a4ee1a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m                     \u001b[0mdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflipud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhours\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fixed_gear'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dtype'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0mdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflipud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhours\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'squid_jigger'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dtype'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                     \u001b[0mdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflipud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhours\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'other_unknown'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dtype'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m                     \u001b[0;31m# dst.write((np.flipud(vessel_hours)/2.).astype(profile['dtype']), indexes=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mrasterio/_base.pyx\u001b[0m in \u001b[0;36mrasterio._base.DatasetReader.__exit__ (rasterio/_base.c:5811)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mrasterio/_base.pyx\u001b[0m in \u001b[0;36mrasterio._base.DatasetReader.close (rasterio/_base.c:5513)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mrasterio/_base.pyx\u001b[0m in \u001b[0;36mrasterio._base.DatasetReader.stop (rasterio/_base.c:5429)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/logging/__init__.pyc\u001b[0m in \u001b[0;36mdebug\u001b[0;34m(self, msg, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_checkLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m         \"\"\"\n\u001b[1;32m   1147\u001b[0m         \u001b[0mLog\u001b[0m \u001b[0;34m'msg % args'\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mseverity\u001b[0m \u001b[0;34m'DEBUG'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "d = datetime(2015,1,1)\n",
    "\n",
    "for i in range(365*2+100):\n",
    "    # print d + timedelta(days=i)\n",
    "    thedate = yyyymmdd = datetime.strftime(d + timedelta(days=i),\"%Y%m%d\")\n",
    "#     command = '''python Make_Rasters_201704011.py {yyyymmdd}'''.format(yyyymmdd=yyyymmdd)\n",
    "#     commands.append(command)\n",
    "#     thedate = \"20150103\" \n",
    "\n",
    "\n",
    "    path_to_csv_zip = \"data/dailytables/fishing_vessel_effort_iso3_gears/zips/\"\n",
    "    path_to_tif =   \"data/dailytables/fishing_vessel_effort_iso3_gears/tifs/\"\n",
    "    path_to_csv_zip_iso3 = \"data/dailytables/fishing_vessel_effort_iso3_gears/iso3s/\"\n",
    "\n",
    "    # codes = {}\n",
    "    # all_codes = []\n",
    "    # with open('iso3.csv','rU') as csvfile:\n",
    "    #     reader = csv.DictReader(csvfile)\n",
    "    #     for row in reader:\n",
    "    #         iso3 = row['iso3']\n",
    "    #         code = row['code']\n",
    "    #         if iso3 not in codes:\n",
    "    #             codes[iso3] = []\n",
    "    #         codes[iso3].append(code)\n",
    "    #         all_codes.append(code)\n",
    "\n",
    "\n",
    "    yyyy = thedate[:4]\n",
    "    mm = thedate[4:6]\n",
    "    dd = thedate[6:8]\n",
    "\n",
    "\n",
    "    query = '''\n",
    "    SELECT\n",
    "      FLOOR(lat*10) lat_bin,\n",
    "      FLOOR(lon*10) lon_bin,\n",
    "      SUM(hours) hours,\n",
    "      if(inferred_label is null, \"unknown\",inferred_label) AS label,\n",
    "      if(iso3 is null, \"UNK\", iso3) as iso3\n",
    "    FROM (\n",
    "      SELECT\n",
    "        mmsi,\n",
    "        lat,\n",
    "        lon,\n",
    "        hours,\n",
    "        flag_iso3 AS iso3\n",
    "      FROM\n",
    "        [world-fishing-827:gfw_research.FAO${thedate}]\n",
    "      WHERE\n",
    "        measure_new_score > .5 \n",
    "        and seg_id NOT IN (\n",
    "        SELECT\n",
    "          seg_id\n",
    "        FROM\n",
    "          [world-fishing-827:gfw_published.segments],\n",
    "        WHERE\n",
    "          valid_positions < 10\n",
    "          AND satellite_positions = 0)) a\n",
    "    LEFT JOIN (\n",
    "      SELECT\n",
    "        mmsi,\n",
    "        inferred_label\n",
    "      FROM\n",
    "        [gfw_research.vessel_info_20170405]\n",
    "      WHERE\n",
    "        year={yyyy}) b\n",
    "    ON\n",
    "      a.mmsi = b.mmsi\n",
    "    GROUP BY\n",
    "      label,\n",
    "      iso3,\n",
    "      lat_bin,\n",
    "      lon_bin\n",
    "    ORDER BY\n",
    "      iso3,\n",
    "      label,\n",
    "    '''.format(thedate=thedate,yyyy=yyyy)\n",
    "\n",
    "\n",
    "    table = \"fishing_effort_\"+thedate\n",
    "    gcs_path = \"gs://david-scratch/\"+table+\".zip\"\n",
    "    local_path = path_to_csv_zip+table+\".zip\"\n",
    "    \n",
    "    print thedate\n",
    "\n",
    "    if not os.path.isfile(local_path): \n",
    "        bigq = BigQuery()\n",
    "        query_job = bigq.async_query(proj_id, query, dataset, table)\n",
    "        bigq.poll_job(query_job)\n",
    "        extract_job = bigq.async_extract_query(query_job, gcs_path)\n",
    "        bigq.poll_job(extract_job)\n",
    "        gs_mv(gcs_path, local_path)\n",
    "\n",
    "    one_over_cellsize = 10\n",
    "    cellsize = .1\n",
    "    num_lats = 180 * one_over_cellsize\n",
    "    num_lons = 360 * one_over_cellsize\n",
    "\n",
    "\n",
    "    profile = {\n",
    "                'crs': 'EPSG:4326',\n",
    "                'nodata': -9999,\n",
    "                'dtype': rio.float32,\n",
    "                'height': num_lats,\n",
    "                'width': num_lons,\n",
    "                'count': 6,\n",
    "                'driver': \"GTiff\",\n",
    "                'transform': affine.Affine(float(cellsize), 0, -180, \n",
    "                                           0, -float(cellsize), 90),\n",
    "                'TILED': 'YES',\n",
    "                'BIGTIFF': 'NO',\n",
    "                'INTERLEAVE': 'BAND',\n",
    "                'COMPRESS': 'DEFLATE',\n",
    "                'PREDICTOR': '3'\n",
    "            }\n",
    "\n",
    "    hours = {}\n",
    "    hours['trawlers'] = np.zeros(shape=(num_lats,num_lons))\n",
    "    hours['drifting_longlines'] = np.zeros(shape=(num_lats,num_lons))\n",
    "    hours['purse_seines'] = np.zeros(shape=(num_lats,num_lons))\n",
    "    hours['fixed_gear'] = np.zeros(shape=(num_lats,num_lons))\n",
    "    hours['squid_jigger'] = np.zeros(shape=(num_lats,num_lons))\n",
    "    hours['other_unknown'] = np.zeros(shape=(num_lats,num_lons))\n",
    "    \n",
    "    with gzip.open(local_path, 'rb') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "\n",
    "        \n",
    "        n = 0\n",
    "        for row in reader:\n",
    "            if n == 0:\n",
    "                iso3 = row['iso3']\n",
    "                n = 1\n",
    "            if row['iso3'] != iso3:  \n",
    "#                 print hours['trawlers'].sum()\n",
    "\n",
    "                # # Read bands individually and write individually\n",
    "                # with rio.open('RGB.byte.tif') as src, \\\n",
    "                #         rio.open('individual.tif', 'w', **src.profile) as dst:\n",
    "                #     for bidx in range(1, src.count + 1):\n",
    "                #         data = src.read(bidx)\n",
    "                #         dst.write(data, indexes=bidx)\n",
    "\n",
    "                # Kevin says You also want the GeoTIFF creation option `PHOTOMETRIC=MINISBLACK`.  \n",
    "                # If an image has 3+ bands of type Byte GDAL will assume `PHOTOMETRIC=RGB`\n",
    "                os.system(\"mkdir \"+path_to_tif + iso3 )\n",
    "                out_tif = path_to_tif + iso3 +\"/\"+yyyy+\"-\"+mm+\"-\"+dd+\".tif\"\n",
    "                with rio.open(out_tif, 'w', **profile) as dst:\n",
    "                    dst.write(np.flipud(hours['trawlers']).astype(profile['dtype']), indexes=1)\n",
    "                    dst.write(np.flipud(hours['drifting_longlines']).astype(profile['dtype']), indexes=2)\n",
    "                    dst.write(np.flipud(hours['purse_seines']).astype(profile['dtype']), indexes=3)\n",
    "                    dst.write(np.flipud(hours['fixed_gear'] ).astype(profile['dtype']), indexes=4)\n",
    "                    dst.write(np.flipud(hours['squid_jigger']).astype(profile['dtype']), indexes=5)\n",
    "                    dst.write(np.flipud(hours['other_unknown']).astype(profile['dtype']), indexes=6)\n",
    "                    # dst.write((np.flipud(vessel_hours)/2.).astype(profile['dtype']), indexes=2)\n",
    "\n",
    "                hours = {}\n",
    "                hours['trawlers'] = np.zeros(shape=(num_lats,num_lons))\n",
    "                hours['drifting_longlines'] = np.zeros(shape=(num_lats,num_lons))\n",
    "                hours['purse_seines'] = np.zeros(shape=(num_lats,num_lons))\n",
    "                hours['fixed_gear'] = np.zeros(shape=(num_lats,num_lons))\n",
    "                hours['squid_jigger'] = np.zeros(shape=(num_lats,num_lons))\n",
    "                hours['other_unknown'] = np.zeros(shape=(num_lats,num_lons))\n",
    "                iso3 = row['iso3']\n",
    "\n",
    "            lat = int(row['lat_bin'])\n",
    "            lon = int(row['lon_bin'])   \n",
    "            if lat<90*one_over_cellsize and \\\n",
    "            lat>-90*one_over_cellsize and lon>-180*one_over_cellsize and lon<180*one_over_cellsize:\n",
    "                label = row['label']\n",
    "                if label not in [\"drifting_longlines\",\"fixed_gear\",\"squid_jigger\", \"purse_seines\",\"trawlers\"]:\n",
    "                    label = \"other_unknown\"\n",
    "                lat_index = lat+90*one_over_cellsize\n",
    "                lon_index = lon+180*one_over_cellsize\n",
    "                hours[label][lat_index][lon_index] = float(row['hours'])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
